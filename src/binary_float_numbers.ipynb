{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('venv')",
   "display_name": "Python 3.8.6 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "86f5510f37a73bccba776b29d689d77308b2249fed85d6de7b84d5b4c47e30c2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Sintax directed translate: Binary float numbers\n",
    "\n",
    "Design of the scheme translation and SLY implementation of a language that translate binary float numbers to decimal.\n",
    "\n",
    "### Translation Scheme Design\n",
    "\n",
    "\n",
    "| Sintactic Rules        | Semantic Rules                                                |\n",
    "|------------------------|---------------------------------------------------------------|\n",
    "| num -> sec_1 '.' sec_2 | num.v := sec_1.v + sec_2.v / 2 ^ sec_2.lon                    |\n",
    "| sec -> sec_1 dig       | sec.v := sec_1.v * 2 + dig.v **and** sec.lon := sec_1.lon + 1 |\n",
    "| sec -> dig             | sec.v := dig.v **and** sec.long := 1                          |\n",
    "| dig -> '0'             | dig.v := 0                                                    |\n",
    "| dig -> '1'             | dig.v := 1                                                    |\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# SLY Implementation\n",
    "\n",
    "### Implementing Lexer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "class Scanner(Lexer):\n",
    "    tokens = {DIG}\n",
    "    literals = {'.'}\n",
    "\n",
    "    # ignore whitespace and tabs\n",
    "    ignore = '\\t'\n",
    "\n",
    "    # Regular expressoins rules for tokens\n",
    "    DIG = r'[01]'\n",
    "\n",
    "    # Error handling rule\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character '{}'\".format(t.value[0]))\n",
    "        self.index += 1"
   ]
  },
  {
   "source": [
    "Testing our Lexer analyzer:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "type = DIG, value 1\ntype = DIG, value 0\ntype = DIG, value 1\ntype = DIG, value 0\ntype = DIG, value 1\ntype = DIG, value 0\ntype = DIG, value 1\ntype = DIG, value 0\ntype = ., value .\ntype = DIG, value 1\ntype = DIG, value 0\nIllegal character &#39;o&#39;\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = '10101010.10'\n",
    "    lexer = Scanner()\n",
    "    for token in lexer.tokenize(data):\n",
    "        print('type = {}, value {}'.format(token.type, token.value))\n"
   ]
  }
 ]
}