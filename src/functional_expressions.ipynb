{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sintax directed translate\n",
    "\n",
    "Design translation scheme (offset parameters Pascal style. That is, the parameters are put on the stack form left ro right)\n",
    "\n",
    "### Grammar:\n",
    "\n",
    "```\n",
    "Def -> ID ID Resto\n",
    "Resto -> ‘,’ Tipo ID Resto\n",
    "Resto -> epsilon\n",
    "Tipo -> INT\n",
    "Tipo -> CHAR\n",
    "Tipo -> FLOAT\n",
    "```\n",
    "\n",
    "### Example:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "`f(int a, float b, char c)`\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Offset de c = 4\n",
    "Offset de b = 4 + sizeof(char)\n",
    "Offset de a = 4 + sizeof(char) + sizeof(float)\n",
    "\n",
    "```\n",
    "\n",
    "# Implementing the lexical analyzer (Lexer)\n",
    "\n",
    "First we have to import the lexer from sly:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [],
   "source": [
    "from sly import Lexer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we have to define our lexical analyzer, creating a class that inherits from Lexer and define the tokens and literals.\n",
    "To avoid the errors from blank characters, add it to ignore variable (in this case we will ignore blank spaces and tabs).\n",
    "ID is defined using a *re* so be careful with that because that definition matches the types. So you have to add\n",
    "the special as special cases of *ID* definitions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "class Scanner(Lexer):\n",
    "    tokens = {ID, INT, FLOAT, CHAR}\n",
    "    literals = {','}\n",
    "\n",
    "    #ignore whitespace and tabulation\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    # Regular expression rules for tokens\n",
    "\n",
    "    ID = r'[a-zA-Z][\\w_]*'\n",
    "\n",
    "    # special cases\n",
    "\n",
    "    ID['int'] = INT\n",
    "    ID['float'] = FLOAT\n",
    "    ID['char'] = CHAR\n",
    "\n",
    "    # Error handling rule\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character {}\".format(t.value[0]))\n",
    "        self.index += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test our Lexer analyzer:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type = INT, value = int\n",
      "type = ID, value = a\n",
      "type = ,, value = ,\n",
      "type = FLOAT, value = float\n",
      "type = ID, value = b\n",
      "type = ,, value = ,\n",
      "type = CHAR, value = char\n",
      "type = ID, value = c\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = \"int a, float b, char c\"\n",
    "    lexer = Scanner()\n",
    "    for token in lexer.tokenize(data):\n",
    "        print('type = {}, value = {}'.format(token.type, token.value))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing syntactic analyzer (Parser)\n",
    "\n",
    "To implement the grammar rules, we will implement a Parser first import Parser from sly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "from sly import Parser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will do the same that we do to implement the Lexer, create a new class that inherits from Parser, pass the tokens\n",
    "from the lexer to our parser, and define the grammar rules."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "class FunctionParser(Parser):\n",
    "    tokens = Scanner.tokens\n",
    "\n",
    "    @_('tipo ID resto')\n",
    "    def def_(self, p):\n",
    "        print('Offset de {} = 4'.format(p.ID) + p.resto)\n",
    "\n",
    "    @_('\",\" tipo ID resto')\n",
    "    def resto(self, p):\n",
    "        print('Offset de {} = 4'.format(p.ID) + p.resto)\n",
    "        return p.resto +' + sizeof({})'.format(p.tipo)\n",
    "    @_('')\n",
    "    def resto(self, p):\n",
    "        return ''\n",
    "    @_('INT', 'FLOAT', 'CHAR')\n",
    "    def tipo(self, p):\n",
    "        return p[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the parser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset de c = 4\n",
      "Offset de b = 4 + sizeof(char)\n",
      "Offset de a = 4 + sizeof(char) + sizeof(float)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    lexer = Scanner()\n",
    "    parser = FunctionParser()\n",
    "    string = \"int a, float b, char c\"\n",
    "    parser.parse(lexer.tokenize(string))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}